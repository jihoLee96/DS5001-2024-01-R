{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabad3fc-8e69-434d-b068-6ed0a114b9be",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "Course:   DS 5001\n",
    "Module:   92 Helper Notebooks\n",
    "Topic:    Using SpaCy \n",
    "Author:   R.C. Alvarado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa4603-604d-4d61-9e0a-6927f2fd81ae",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "## How to install\n",
    "\n",
    "* `conda install -c conda-forge spacy`\n",
    "* `python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400639d-a68b-41dc-9200-a7d2bbf0deed",
   "metadata": {},
   "source": [
    "## About SpaCy\n",
    "\n",
    "* More than a library; it is an **entire platform** for text processing. It is designed to be integrated into production-level data products.\n",
    "* Designed for performance. It uses **best of breed** tools and can be somewhat opaque.\n",
    "* **A replacement for NLTK**, especially for linguistic annonation in the preprocessing stages. It can work with Gensim and SciKit Learn.\n",
    "* Designed to be **accessed by API**, not be dumping to a database -- but it can be done.\n",
    "* Should be installed in **its own Python environment**.  \n",
    "  * For example, do `conda create -n spacy` and then do `conda activate spacy`. From there, install SpaCy and everything else you need for your project.\n",
    "\n",
    "## SpaCy's Object Model\n",
    "\n",
    "Note: this is not a true data model, but an object model that bundles data with algorithms (methods).\n",
    "\n",
    "<img src=\"images/spacy-architecture.svg\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f6147-0299-4e2b-9b04-1c30050559c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b575e-413e-4b8c-9516-f07f07f86adb",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7836122f-78d9-421e-af38-898202a9481e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "local_lib = config['DEFAULT']['local_lib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea3a145-6941-4d31-b3b7-ca44de274303",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = 'austen-melville'\n",
    "OHCO = ['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df406a5d-157c-4131-a359-6e62d275f316",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a21c5f10-5c41-401d-9ad3-fdfb932ce403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm as tqdm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19102d58-9eaf-4ef1-ab1e-c420fd534e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf99bfb-d44e-44fa-a0c2-ff33746b48d1",
   "metadata": {},
   "source": [
    "# Import CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327480db-40eb-4854-97a5-159df9f20c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = pd.read_csv(f\"{output_dir}/{data_prefix}-LIB.csv\").set_index(OHCO[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895fffc2-eda6-4ca8-88a6-2aed60aa10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = pd.read_csv(f\"{output_dir}/{data_prefix}-CORPUS.csv\").set_index(OHCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23dc3922-4ea3-49e4-877e-3e02649ed611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>pos_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">105</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>('Sir', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Sir</td>\n",
       "      <td>sir</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('Walter', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Walter</td>\n",
       "      <td>walter</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('Elliot,', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Elliot,</td>\n",
       "      <td>elliot</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('of', 'IN')</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('Kellynch', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Kellynch</td>\n",
       "      <td>kellynch</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       pos_tuple  pos  \\\n",
       "book_id chap_id para_num sent_num token_num                             \n",
       "105     1       1        0        0               ('Sir', 'NNP')  NNP   \n",
       "                                  1            ('Walter', 'NNP')  NNP   \n",
       "                                  2           ('Elliot,', 'NNP')  NNP   \n",
       "                                  3                 ('of', 'IN')   IN   \n",
       "                                  4          ('Kellynch', 'NNP')  NNP   \n",
       "\n",
       "                                            token_str  term_str pos_group  \n",
       "book_id chap_id para_num sent_num token_num                                \n",
       "105     1       1        0        0               Sir       sir        NN  \n",
       "                                  1            Walter    walter        NN  \n",
       "                                  2           Elliot,    elliot        NN  \n",
       "                                  3                of        of        IN  \n",
       "                                  4          Kellynch  kellynch        NN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e868d8-402c-4ea1-9f7e-2d88e73b6d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gather_docs(CORPUS, ohco_level, str_col='term_str', glue=' '):\n",
    "    OHCO = CORPUS.index.names\n",
    "    CORPUS[str_col] = CORPUS[str_col].astype('str')\n",
    "    DOC = CORPUS.groupby(OHCO[:ohco_level])[str_col].apply(lambda x: glue.join(x)).to_frame('doc_str')\n",
    "    return DOC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e371b1-e28e-425d-b83c-87f70bb01e2e",
   "metadata": {},
   "source": [
    "## Gather CHAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2c81ad-6569-4395-9c4c-114ef57c961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTS = gather_docs(CORPUS, 4) # We do this to preserve sentence boundaries in CHAPs\n",
    "CHAPS = gather_docs(SENTS, 2, str_col='doc_str', glue='. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "085e0033-c1b4-41cf-8c4f-c8d4b9a920df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>doc_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">105</th>\n",
       "      <th>1</th>\n",
       "      <td>sir walter elliot of kellynch hall in somerset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr shepherd a civil cautious lawyer who whatev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i must take leave to observe sir walter said m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he was not mr wentworth the former curate of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on the morning appointed for admiral and mrs c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">34970</th>\n",
       "      <th>110</th>\n",
       "      <td>in the midst of all these mental confusions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>gaining the apostles and leaving his two compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>pierre passed on to a remote quarter of the bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>that sundown pierre stood solitary in a low du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>at night the squat framed asthmatic turnkey tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           doc_str\n",
       "book_id chap_id                                                   \n",
       "105     1        sir walter elliot of kellynch hall in somerset...\n",
       "        2        mr shepherd a civil cautious lawyer who whatev...\n",
       "        3        i must take leave to observe sir walter said m...\n",
       "        4        he was not mr wentworth the former curate of m...\n",
       "        5        on the morning appointed for admiral and mrs c...\n",
       "...                                                            ...\n",
       "34970   110      in the midst of all these mental confusions th...\n",
       "        111      gaining the apostles and leaving his two compa...\n",
       "        112      pierre passed on to a remote quarter of the bu...\n",
       "        113      that sundown pierre stood solitary in a low du...\n",
       "        114      at night the squat framed asthmatic turnkey tr...\n",
       "\n",
       "[1185 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e8bac-c187-484e-a445-b81f43358e11",
   "metadata": {},
   "source": [
    "# Use SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a8c85-a4ef-4e7b-b703-d924bd2d49ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Statistical Models\n",
    "\n",
    "These are also called \"trained pipelines\" in the documentation.\n",
    "\n",
    "**Trained pipelines for English:**\n",
    "* `en_core_web_sm`: English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
    "* `en_core_web_md`:  English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
    "* `en_core_web_lg`:  English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
    "* `en_core_web_trf`: English transformer pipeline (roberta-base). Components: transformer, tagger, parser, ner, attribute_ruler, lemmatizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250019b7-1625-42e0-acad-c651333518c0",
   "metadata": {},
   "source": [
    "<img \n",
    "     width=\"500\"\n",
    "     src=\"https://d33wubrfki0l68.cloudfront.net/3ad0582d97663a1272ffc4ccf09f1c5b335b17e9/7f49c/pipeline-fde48da9b43661abcdf62ab70a546d71.svg\"/>\n",
    "     \n",
    "See <a href=\"https://spacy.io/usage/processing-pipelines\">the docs</a> for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "682b1b4a-511a-4698-a12d-3c1f5a3c08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pipeline = 'en_core_web_md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98329880-62f0-46cd-b6d2-be35136aaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download {trained_pipeline}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae0109b-4c1e-4911-991f-0be54959925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = spacy.nlp(doc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db0ddcb-e5ff-4518-b8b9-80f5b65b4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(trained_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc8c84-b857-47e6-9d91-a5d55a153b5b",
   "metadata": {},
   "source": [
    "## Generate Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a780478f-aa37-4c66-b1e9-37eb87043029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipleline = [\"tok2vec\", \"tagger\", \"parser\", \"ner\", \"attribute_ruler\", \"lemmatizer\"]\n",
    "# disable= [\"attribute_ruler\", \"lemmatizer\", \"parser\"]\n",
    "disable = []\n",
    "DOCS = [doc.to_json() for doc in nlp.pipe(CHAPS.doc_str.values, disable=disable)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6002ed4-d82a-4b65-b347-2ea267e69115",
   "metadata": {},
   "source": [
    "## Convert to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b7ed0-948d-4972-9ceb-55f8509fabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(DOCS[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d2f96-ca8c-495d-b161-781054120472",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf90f6-9d6a-4d2d-a09b-4b7c2649c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = {f:[] for f in features}\n",
    "for i in range(len(DOCS)):    \n",
    "    text = DOCS[i]['text']\n",
    "    for feature in features[1:]:\n",
    "        df = pd.DataFrame(DOCS[i][feature])\n",
    "        df[f'{feature[:-1]}_str'] = df.apply(lambda x: text[x.start:x.end], 1)\n",
    "        df['doc_id'] = i\n",
    "        feature_data[feature].append(df)\n",
    "    \n",
    "class mySpaCy(): pass\n",
    "spcy = mySpaCy()\n",
    "for feature in features[1:]:\n",
    "    setattr(spcy, feature, pd.concat(feature_data[feature]).rename_axis(f'{feature[:-1]}_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6b503-3429-4b85-8469-d10d39b01bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a816d7-2bcd-4ab6-866c-668150149ac8",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812a1b2-57e8-449f-bc94-43f5d2de1378",
   "metadata": {},
   "source": [
    "### TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebf75a-09a0-40c6-918c-ae3452153f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spcy.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7efe93d-73d5-4595-bfb8-40244cf15057",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a4e44f-b23c-4695-9a8a-e442c033a455",
   "metadata": {},
   "source": [
    "### VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef95ec-3607-449e-8722-ef570bd68539",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.VOCAB = spcy.tokens.value_counts('token_str').to_frame('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e276617-f446-42a9-b17b-6d2117005b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.VOCAB['max_pos'] = spcy.tokens.value_counts(['token_str','pos']).unstack().idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfd824-7d08-40d5-a0b6-8a4807217469",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.VOCAB[spcy.VOCAB.max_pos == 'PROPN'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883d56b9-e45d-425b-8185-0c6b861dcfd3",
   "metadata": {},
   "source": [
    "### ENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738ab312-1e99-4385-b9fa-a79862e59d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.ents.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab373a-e89b-4610-b290-22c6eee426a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.ents[spcy.ents.label=='PERSON'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13aeba-4106-494d-9962-44cb3ef6aea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.ents[spcy.ents.label=='PERSON'].value_counts(['doc_id','ent_str']).unstack().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2a5b2-7756-4f3e-a0f3-b23c92fccec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.ents[spcy.ents.label=='ORG'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d11453-1963-45b5-9fbf-2cfa7bf1b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.ents[spcy.ents.label=='DATE'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab097b5-7ea7-4f20-b5c6-952687017c32",
   "metadata": {},
   "source": [
    "### SENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2d872-21ca-4c4a-b003-0fa58eb47da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spcy.sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac226b3b-3881-4ff7-8313-81160019a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372eb39-e3a4-4a7c-90de-a758aba02c59",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b144dc-22a1-4f2a-8e4f-dce29c37fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07183714-450d-427f-963e-e92b28657084",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sqlite3.connect(f\"{data_home}/output/space-demo.db\") as db:\n",
    "    for feature in features[1:]:\n",
    "        getattr(spcy, feature).to_sql(feature, db, index=True, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfedbc-3e76-4a56-876e-f6a00deb373b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
