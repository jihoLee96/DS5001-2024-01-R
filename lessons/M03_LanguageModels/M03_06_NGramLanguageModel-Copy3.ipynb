{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6084ed44-0d7d-4833-a10a-1aac3f73cb13",
   "metadata": {},
   "source": [
    "# M03 Homework\n",
    "\n",
    "```yaml\n",
    "Course:  DS 5001\n",
    "Module:  M03 Language Models\n",
    "Author:  JiHo Lee (qcx6hb)\n",
    "Date:    4 February 2024\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d375cb87",
   "metadata": {},
   "source": [
    "### For setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a30beeb-1f4a-46bb-b42a-c637ae0d43ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  C:\\DS5001\\DS5001_2024_01_R\\..\\data\\gutenberg\\pg42324.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^(?:INTRODUCTION|PREFACE|LETTER|CHAPTER)\\b\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by delimitter [.?!;:]+\n",
      "Parsing OHCO level 3 token_num by delimitter [\\s',-]+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../../env.ini\")\n",
    "data_dir = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "\n",
    "data_dir  = data_dir.replace('/', '\\\\')\n",
    "output_dir  = output_dir.replace('/', '\\\\')\n",
    "\n",
    "ngrams = 2\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "\n",
    "# data_dir = output_dir\n",
    "OHCO = ['chap_id','para_num','sent_num','token_num']\n",
    "\n",
    "text_file = f\"{data_dir}/gutenberg/pg42324.txt\"\n",
    "csv_token  = f\"{output_dir}/austen-combo-TOKENS.csv\" # The file we will create\n",
    "csv_vocab = f\"{output_dir}/austen-combo-VOCAB.csv\" \n",
    "\n",
    "text_file = text_file.replace('/', '\\\\')\n",
    "csv_token = csv_token.replace('/', '\\\\')\n",
    "csv_vocab = csv_vocab.replace('/', '\\\\')\n",
    "\n",
    "from textimporter import TextImporter\n",
    "from textparser import TextParser\n",
    "\n",
    "src_file = text_file\n",
    "# ohco_pats = [('chap', r'^(?:INTRODUCTION|PREFACE|LETTER|CHAPTER)\\.?\\b', 'm')]\n",
    "ohco_pats = [('chap', r'^(?:INTRODUCTION|PREFACE|LETTER|CHAPTER)\\b', 'm')]\n",
    "clip_pats = [r'START', r'END']\n",
    "\n",
    "test= TextImporter(src_file=src_file, ohco_pats=ohco_pats, clip_pats=clip_pats)\n",
    "test.import_source().parse_tokens()\n",
    "\n",
    "TOKEN = test.TOKENS\n",
    "test.extract_vocab()\n",
    "VOCAB = test.VOCAB\n",
    "\n",
    "# VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['modified_term_str'] = VOCAB.index\n",
    "VOCAB.loc[(VOCAB.n == 1) & (VOCAB.n_chars < 3), 'modified_term_str'] = \"<UNK>\"\n",
    "\n",
    "TOKEN['modified_term_str'] = TOKEN.term_str.map(VOCAB.modified_term_str)\n",
    "# TOKEN[TOKEN.modified_term_str == '<UNK>'].sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa48efa0-5cd5-48c3-b2ed-b3d80808e8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def token_to_padded(token, grouper=['sent_num'], term_str='term_str'):\n",
    "    ohco = token.index.names # We preserve these since they get lost in the shuffle\n",
    "#     print(ohco)\n",
    "    padded = token.groupby(grouper)\\\n",
    "        .apply(lambda x: '<s> ' + ' '.join(x[term_str]) + ' </s>')\\\n",
    "        .apply(lambda x: pd.Series(x.split()))\\\n",
    "        .stack().to_frame('term_str')\n",
    "#     print(padded)\n",
    "#     print(ohco)\n",
    "    padded.index.names = ohco \n",
    "    return padded\n",
    "def padded_to_ngrams(padded, grouper=['sent_num'], n=2):\n",
    "    \n",
    "    ohco = padded.index.names\n",
    "    ngrams = padded.groupby(grouper)\\\n",
    "        .apply(lambda x: pd.concat([x.shift(0-i) for i in range(n)], axis=1))\\\n",
    "        .reset_index(drop=True)\n",
    "    ngrams.index = padded.index\n",
    "    ngrams.columns = widx\n",
    "\n",
    "    # ngrams = pd.concat([padded.shift(0-i) for i in range(n)], axis=1)\n",
    "    # ngrams.index.name = 'ngram_num'\n",
    "    # ngrams.columns = widx\n",
    "    # ngrams = ngrams.fillna('<EOF>')\n",
    "    \n",
    "    return ngrams\n",
    "PADDED = token_to_padded(TOKEN, grouper=OHCO[:3], term_str='modified_term_str')\n",
    "NGRAMS = padded_to_ngrams(PADDED, OHCO[:3], ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2eeec1",
   "metadata": {},
   "source": [
    "### Question 1.\n",
    "1. List six words that precede the word \"monster,\" excluding stop words (and sentence boundary markers). Stop words include 'a', 'an', 'the', 'this', 'that', etc. Hint: use the df.query() method.\n",
    "\n",
    "Answers: miserable, abhorred, detestable, hideous, hellish, gigantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e3d82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>3</th>\n",
       "      <th>17</th>\n",
       "      <th>25</th>\n",
       "      <td>miserable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>8</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>abhorred</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <td>detestable</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>28</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>hideous</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">32</th>\n",
       "      <th>4</th>\n",
       "      <th>9</th>\n",
       "      <th>5</th>\n",
       "      <td>hellish</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>6</th>\n",
       "      <th>2</th>\n",
       "      <td>gigantic</td>\n",
       "      <td>monster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             w0       w1\n",
       "chap_id para_num sent_num token_num                     \n",
       "13      3        17       25          miserable  monster\n",
       "18      8        0        1            abhorred  monster\n",
       "23      25       4        23         detestable  monster\n",
       "24      28       0        1             hideous  monster\n",
       "32      4        9        5             hellish  monster\n",
       "        17       6        2            gigantic  monster"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = ['this', 'the', 'a', '<s>']\n",
    "tmp = NGRAMS.query(\"w1=='monster'\")\n",
    "tmp2 = tmp[~tmp['w0'].isin(['this', 'the', 'a', '<s>'])]\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51518d",
   "metadata": {},
   "source": [
    "### Question 2.\n",
    "2. List the following sentences in ascending order of bigram perplexity according to the language model generated from the text:\n",
    "\n",
    "Answers:\n",
    "\n",
    "I have never seen the aurora borealis.\t\n",
    "\n",
    "The monster is on the ice.\t\n",
    "\n",
    "He never knew the love of a family.\n",
    "\n",
    "Flowers are happy things.\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819d2cf9-0af7-4eca-b800-eb6d7c6f7ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ngrams_to_models(ngrams):\n",
    "    global widx\n",
    "    n = len(ngrams.columns)\n",
    "    model = [None for i in range(n)]\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            model[i] = ngrams.value_counts('w0').to_frame('n')\n",
    "            model[i]['p'] = model[i].n / model[i].n.sum()\n",
    "            model[i]['i'] = np.log2(1/model[i].p)\n",
    "        else:\n",
    "            model[i] = ngrams.value_counts(widx[:i+1]).to_frame('n')    \n",
    "            model[i]['cp'] = model[i].n / model[i-1].n\n",
    "            model[i]['i'] = np.log2(1/model[i].cp)\n",
    "        model[i] = model[i].sort_index()\n",
    "    return model\n",
    "M = ngrams_to_models(NGRAMS)\n",
    "\n",
    "S= \"The monster is on the ice.\\nFlowers are happy things.\\nI have never seen the aurora borealis.\\nHe never knew the love of a family.\"\n",
    "S = S.split('\\n')\n",
    "S = pd.DataFrame(S, columns=['sent_str'])\n",
    "S.index.name='sent_num'\n",
    "\n",
    "# Convert dataframe of sentences to TOKEN with normalized terms\n",
    "K = S.sent_str.apply(lambda x: pd.Series(x.split())).stack().to_frame('token_str')\n",
    "K['term_str'] = K.token_str.str.replace(r\"[\\W_]+\", \"\", regex=True).str.lower()\n",
    "K.index.names = ['sent_num', 'token_num']\n",
    "\n",
    "TEST_SENTS, TEST_TOKENS = S, K\n",
    "TEST_TOKENS.loc[~TEST_TOKENS.term_str.isin(M[0].index), 'term_str'] = \"<UNK>\"\n",
    "# TEST_TOKENS[TEST_TOKENS.term_str == '<UNK>'].value_counts('token_str')\n",
    "TEST_PADDED = token_to_padded(TEST_TOKENS)\n",
    "TEST_NGRAMS = padded_to_ngrams(TEST_PADDED, 'sent_num', 2)\n",
    "\n",
    "def test_model(model, ngrams, sents):\n",
    "    \n",
    "    global widx\n",
    "    \n",
    "    assert len(model) == len(ngrams.columns)\n",
    "    \n",
    "    n = len(model)\n",
    "    ohco = ngrams.index.names\n",
    "    \n",
    "    R = []\n",
    "    for i in range(n):\n",
    "        T = ngrams.merge(M[i], on=widx[:i+1], how='left')\n",
    "        T.index = ngrams.index\n",
    "        T = T.reset_index().set_index(ohco + widx).i #.to_frame(f\"i{i}\")\n",
    "        \n",
    "        # This how we handle unseen combos\n",
    "        T[T.isna()] = T.max()\n",
    "        R.append(T.to_frame(f\"i{i}\"))\n",
    "                \n",
    "    return pd.concat(R, axis=1)\n",
    "R = test_model(M,TEST_NGRAMS, TEST_SENTS)\n",
    "def compute_perplexity(results, test_sents, n=2):\n",
    "    for i in range(n):\n",
    "        test_sents[f\"pp{i}\"] = np.exp2(results.groupby('sent_num')[f\"i{i}\"].mean())\n",
    "    return test_sents\n",
    "\n",
    "PP = compute_perplexity(R, TEST_SENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89d7dfe-6133-42b9-b071-3965b6dc776e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "      <th>pp0</th>\n",
       "      <th>pp1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have never seen the aurora borealis.</td>\n",
       "      <td>299.843636</td>\n",
       "      <td>36.637991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The monster is on the ice.</td>\n",
       "      <td>116.931101</td>\n",
       "      <td>72.914436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He never knew the love of a family.</td>\n",
       "      <td>171.859389</td>\n",
       "      <td>117.836895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers are happy things.</td>\n",
       "      <td>552.541874</td>\n",
       "      <td>358.229326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sent_str         pp0         pp1\n",
       "sent_num                                                                \n",
       "2         I have never seen the aurora borealis.  299.843636   36.637991\n",
       "0                     The monster is on the ice.  116.931101   72.914436\n",
       "3            He never knew the love of a family.  171.859389  117.836895\n",
       "1                      Flowers are happy things.  552.541874  358.229326"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PP.sort_values(by=['pp1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef674cc2-b528-47e6-b0e0-1b1f2ecded3a",
   "metadata": {},
   "source": [
    "### Question 3.\n",
    "3. Using the bigram model represented as a matrix, explore the relationship between bigram pairs using the following lists. Hint: use the .unstack() method on the feature n and then use .loc[] to select the first list from the index, and the second list from the columns.\n",
    "    ['he','she'] to select the indices.\n",
    "    ['said','heard'] to select the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94e61a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pp1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df3 \u001b[38;5;241m=\u001b[39m NGRAMS\u001b[38;5;241m.\u001b[39mpp1\u001b[38;5;241m.\u001b[39munstack(fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pp1'"
     ]
    }
   ],
   "source": [
    "df3 = NGRAMS.pp1.unstack(fill_value=0)\n",
    "# df3.style.background_gradient(cmap='YlGnBu', axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f8efe",
   "metadata": {},
   "source": [
    "### Question 4.\n",
    "4. Generate 20 sentences using the generate_text() function. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389f3c33-3f45-4a71-a195-0cb44591f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 HINDOOS GIVE THE WORLD\n",
      "\n",
      "2 MIEN DURING HIS LECTURE HAD REMOVED MY PREJUDICES AGAINST MODERN CHEMISTS\n",
      "\n",
      "3 LISTEN TO ME HANGING AMONG THE TREES\n",
      "\n",
      "4 I HAD LEARNED FROM THE THROATS OF THE STARS OFTEN DISAPPEARED IN THE ALPS OF SAVOY\n",
      "\n",
      "5 THE CAUSE OF THIS REMARK MY DEAR VICTOR IS NECESSARY TO CALM HER MIND\n",
      "\n",
      "6 AND THE SURROUNDING MOUNTAINS\n",
      "\n",
      "7 \n",
      "\n",
      "8 TUTORED AND REFINED BY BOOKS AND RETIREMENT FROM THE INTERCOURSE OF THE MOUNTAIN OR TRANSVERSELY UPON OTHER TREES\n",
      "\n",
      "9 ALSO TO FORGET MYSELF AND I THOUGHT THAT MY CONVERSATION HAD INTERESTED THE FATHER OF A PROMONTORY FLOURISHING VINEYARDS WITH GREEN SLOPING BANKS AND A SLAVE BY THE SHOCK BUT ENTIRELY REDUCED TO A CONDUCT SO LITTLE WORTHY OF MY AUNT IN HER ALSO\n",
      "\n",
      "10 THE PICTURE OF MY NEW PRECEPTORS I ENTERED\n",
      "\n",
      "11 CONSENTED TO RETURN TO THE PLEASURE I PERCEIVED AS THE SHAPE CAME NEARER SIGHT TREMENDOUS AND OVERWHELMING SOUND\n",
      "\n",
      "12 CONSISTED ENTIRELY OF THE HUMAN FRAME AND INDEED NONE OF OUR GOOD UNCLE THOMAS S LIBRARY\n",
      "\n",
      "13 WAR AGAINST THE PANES AND MY DREAMS WERE AT ONCE DREW TEARS FROM THE POSTURE IN WHICH THE OLD MAN A CONDITION WHICH IN A FEW MISERABLE COWS AND OATMEAL FOR ITS INHABITANTS\n",
      "\n",
      "14 TO LEAVE THE RELICS OF MY SUFFERINGS SHALL ENDURE\n",
      "\n",
      "15 YEARS THEIR ONLY CHILD\n",
      "\n",
      "16 SHOULD BE PACKED TO GO\n",
      "\n",
      "17 AND PEACEFUL WHILE MINE BECAME EVERY MOMENT TO YOU ENCOMPASSED BY A MERCHANTMAN NOW ON ITS SHORES\n",
      "\n",
      "18 I DELIVERED MY\n"
     ]
    }
   ],
   "source": [
    "ngrams = 3\n",
    "widx = [f\"w{i}\" for i in range(ngrams)]\n",
    "\n",
    "NGRAMS = padded_to_ngrams(PADDED, OHCO[:3], ngrams)\n",
    "M = ngrams_to_models(NGRAMS)\n",
    "\n",
    "# TEST_PADDED = token_to_padded(TEST_TOKENS)\n",
    "# TEST_NGRAMS = padded_to_ngrams(TEST_PADDED, 'sent_num', 3)\n",
    "# M = ngrams_to_models(TEST_NGRAMS)\n",
    "\n",
    "def generate_text(M, n=250):\n",
    "    \n",
    "    if len(M) < 3:\n",
    "        raise ValueError(\"Must have trigram model generated.\")\n",
    "    \n",
    "    # Start list of words\n",
    "    first_word = M[1].loc['<s>'].sample(weights='cp').index[0]\n",
    "    \n",
    "    words = ['<s>', first_word]\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        bg = tuple(words[-2:])\n",
    "\n",
    "        # Try trigram model\n",
    "        try:\n",
    "            next_word = M[2].loc[bg].sample(weights='cp').index[0]\n",
    "\n",
    "        # If not found in model, back off ...\n",
    "        except KeyError as e1:\n",
    "            try:\n",
    "                # Get the last word in the bigram\n",
    "                ug = bg[1]\n",
    "                next_word = M[1].loc[ug].sample(weights='cp').index[0]\n",
    "            \n",
    "            except KeyError as e2:\n",
    "                next_word = M[0].sample(weights='p').index[0]\n",
    "                \n",
    "        words.append(next_word)\n",
    "    \n",
    "    \n",
    "    text = ' '.join(words[2:])\n",
    "    print('\\n\\n'.join([str(i+1) + ' ' + line.replace('<s>','')\\\n",
    "        .strip().upper() for i, line in enumerate(text.split('</s>'))]))\n",
    "# generate_text(M)\n",
    "generate_text(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d1e9a",
   "metadata": {},
   "source": [
    "### Question 5.\n",
    "5. Compute the redundancy \n",
    " for each of the n-gram models using the MLE of the joint probability of each ngram type. In other words, for each model, just use the .mle feature as p \n",
    " in computing H.\n",
    " \n",
    " - Does R increase, decrease, or remain the same as the choice of n-gram increases in length?\n",
    " - Hint: Remember that R, where H is the actual entropy of the model and H_max is its maximum entropy\n",
    " \n",
    " - If mle is not a feature in your model, just use p for the unigram model and compute p for the other two models by dividing n by the sum of n\n",
    " - N is computed as the number of all possible combinations for each ngram. So, for the bigram model N is the number of unigrams (i.e. the vocabulary size plus the sentence boundary signs) squared, and for the trigram model the value is cubed, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85c7537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>the</td>\n",
       "      <td>publishers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>publishers</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>publishers</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>standard</td>\n",
       "      <td>novels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">32</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">82</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>darkness</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>darkness</td>\n",
       "      <td>and</td>\n",
       "      <td>distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>distance</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88801 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             w0          w1          w2\n",
       "chap_id para_num sent_num token_num                                    \n",
       "1       0        0        0                 <s>         the  publishers\n",
       "                          1                 the  publishers          of\n",
       "                          2          publishers          of         the\n",
       "                          3                  of         the    standard\n",
       "                          4                 the    standard      novels\n",
       "...                                         ...         ...         ...\n",
       "32      82       1        11                 in    darkness         and\n",
       "                          12           darkness         and    distance\n",
       "                          13                and    distance        </s>\n",
       "                          14           distance        </s>        None\n",
       "                          15               </s>        None        None\n",
       "\n",
       "[88801 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e616eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB\n",
    "n_terms = VOCAB.n.count() # same as vocab.shape[0]\n",
    "H = VOCAB.h.sum()\n",
    "Hmax = np.log2(n_terms)\n",
    "R = 1 - (H/Hmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "634c8c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2733562891486093"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
